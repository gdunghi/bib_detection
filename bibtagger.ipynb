{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0867bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from __future__ import division\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import os\n",
    "import scipy.sparse, scipy.spatial\n",
    "from PIL import Image\n",
    "from pytesseract import image_to_string\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#config for windows\n",
    "#pytesseract.pytesseract.tesseract_cmd = \"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "\n",
    "diagnostics = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "427d8247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SWTScrubber(object):\n",
    "    @classmethod\n",
    "    def scrub(cls, image):\n",
    "        \"\"\"\n",
    "        Apply Stroke-Width Transform to image.\n",
    "\n",
    "        :param filepath: relative or absolute filepath to source image\n",
    "        :return: numpy array representing result of transform\n",
    "        \"\"\"\n",
    "\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # plt.imshow(gray)\n",
    "        # plt.show()\n",
    "\n",
    "        canny, sobelx, sobely, theta = cls._create_derivative(gray)\n",
    "        swt = cls._swt(theta, canny, sobelx, sobely)\n",
    "        shapes = cls._connect_components(swt)\n",
    "        swts, heights, widths, topleft_pts, images = cls._find_letters(swt, shapes)\n",
    "        if(len(swts)==0):\n",
    "            #didn't find any text, probably a bad face\n",
    "            return None\n",
    "\n",
    "        word_images = cls._find_words(swts, heights, widths, topleft_pts, images)\n",
    "        final_mask = np.zeros(swt.shape)\n",
    "        for word in word_images:\n",
    "            final_mask += word\n",
    "        return final_mask\n",
    "\n",
    "    @classmethod\n",
    "    def _create_derivative(cls, img):\n",
    "        edges = cv2.Canny(img, 175, 320, apertureSize=3)\n",
    "        # Create gradient map using Sobel\n",
    "        sobelx64f = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=-1)\n",
    "        sobely64f = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=-1)\n",
    "\n",
    "        theta = np.arctan2(sobely64f, sobelx64f)\n",
    "        if diagnostics:\n",
    "            cv2.imwrite('edges.jpg',edges)\n",
    "            cv2.imwrite('sobelx64f.jpg', np.absolute(sobelx64f))\n",
    "            cv2.imwrite('sobely64f.jpg', np.absolute(sobely64f))\n",
    "            # amplify theta for visual inspection\n",
    "            theta_visible = (theta + np.pi)*255/(2*np.pi)\n",
    "            cv2.imwrite('theta.jpg', theta_visible)\n",
    "        return (edges, sobelx64f, sobely64f, theta)\n",
    "\n",
    "    @classmethod\n",
    "    def _swt(self, theta, edges, sobelx64f, sobely64f):\n",
    "        # create empty image, initialized to infinity\n",
    "        swt = np.empty(theta.shape)\n",
    "        swt[:] = np.Infinity\n",
    "        rays = []\n",
    "\n",
    "\n",
    "        # now iterate over pixels in image, checking Canny to see if we're on an edge.\n",
    "        # if we are, follow a normal a ray to either the next edge or image border\n",
    "        # edgesSparse = scipy.sparse.coo_matrix(edges)\n",
    "        step_x_g = -1 * sobelx64f\n",
    "        step_y_g = -1 * sobely64f\n",
    "        mag_g = np.sqrt( step_x_g * step_x_g + step_y_g * step_y_g )\n",
    "        grad_x_g = step_x_g / mag_g\n",
    "        grad_y_g = step_y_g / mag_g\n",
    "\n",
    "        for x in range(edges.shape[1]):\n",
    "            for y in range(edges.shape[0]):\n",
    "                if edges[y, x] > 0:\n",
    "                    step_x = step_x_g[y, x]\n",
    "                    step_y = step_y_g[y, x]\n",
    "                    mag = mag_g[y, x]\n",
    "                    grad_x = grad_x_g[y, x]\n",
    "                    grad_y = grad_y_g[y, x]\n",
    "                    ray = []\n",
    "                    ray.append((x, y))\n",
    "                    prev_x, prev_y, i = x, y, 0\n",
    "                    while True:\n",
    "                        i += 1\n",
    "                        \n",
    "                        #edited\n",
    "                        if math.isnan(grad_x):\n",
    "                            break\n",
    "                      \n",
    "                        cur_x = math.floor(x + grad_x * i)\n",
    "                        cur_y = math.floor(y + grad_y * i)\n",
    "                            \n",
    "                        if cur_x != prev_x or cur_y != prev_y:\n",
    "                            # we have moved to the next pixel!\n",
    "                            try:\n",
    "                                # Detect if we have just \"stepped through\" a line on the diagonal\n",
    "                                if (prev_x != x and prev_y != y and cur_x != prev_x and cur_y != prev_y):\n",
    "                                    if edges[cur_y, prev_x] > 0 and edges[prev_y, cur_x] > 0:\n",
    "                                        break\n",
    "\n",
    "                                if edges[cur_y, cur_x] > 0:\n",
    "                                    # found edge,\n",
    "                                    ray.append((cur_x, cur_y))\n",
    "                                    theta_point = theta[y, x]\n",
    "                                    alpha = theta[cur_y, cur_x]\n",
    "                                    val = grad_x * -grad_x_g[cur_y, cur_x] + grad_y * -grad_y_g[cur_y, cur_x]\n",
    "                                    if (val < -1.0):\n",
    "                                        val = -1.0\n",
    "                                    if (val > 1.0):\n",
    "                                        val = 1.0\n",
    "                                    if math.acos(val) < np.pi/2.0:\n",
    "                                        thickness = math.sqrt( (cur_x - x) * (cur_x - x) + (cur_y - y) * (cur_y - y) )\n",
    "                                        for (rp_x, rp_y) in ray:\n",
    "                                            swt[rp_y, rp_x] = min(thickness, swt[rp_y, rp_x])\n",
    "                                        rays.append(ray)\n",
    "                                    break\n",
    "                                # this is positioned at end to ensure we don't add a point beyond image boundary\n",
    "                                ray.append((cur_x, cur_y))\n",
    "                            except IndexError:\n",
    "                                # reached image boundary\n",
    "                                break\n",
    "                            prev_x = cur_x\n",
    "                            prev_y = cur_y\n",
    "\n",
    "        # Compute median SWT\n",
    "        for ray in rays:\n",
    "            median = np.median([swt[y, x] for (x, y) in ray])\n",
    "            for (x, y) in ray:\n",
    "                swt[y, x] = min(median, swt[y, x])\n",
    "        if diagnostics:\n",
    "            cv2.imwrite('swt.jpg', swt * 100)\n",
    "\n",
    "        return swt\n",
    "\n",
    "    @classmethod\n",
    "    def _connect_components(cls, swt):\n",
    "        # STEP: Compute distinct connected components\n",
    "        # Implementation of disjoint-set\n",
    "        class Label(object):\n",
    "            def __init__(self, value):\n",
    "                self.value = value\n",
    "                self.parent = self\n",
    "                self.rank = 0\n",
    "            def __eq__(self, other):\n",
    "                if type(other) is type(self):\n",
    "                    return self.value == other.value\n",
    "                else:\n",
    "                    return False\n",
    "            def __ne__(self, other):\n",
    "                return not self.__eq__(other)\n",
    "\n",
    "        ld = {}\n",
    "\n",
    "        def MakeSet(x):\n",
    "            try:\n",
    "                return ld[x]\n",
    "            except KeyError:\n",
    "                item = Label(x)\n",
    "                ld[x] = item\n",
    "                return item\n",
    "\n",
    "        def Find(item):\n",
    "            # item = ld[x]\n",
    "            if item.parent != item:\n",
    "                item.parent = Find(item.parent)\n",
    "            return item.parent\n",
    "\n",
    "        def Union(x, y):\n",
    "            \"\"\"\n",
    "            :param x:\n",
    "            :param y:\n",
    "            :return: root node of new union tree\n",
    "            \"\"\"\n",
    "            x_root = Find(x)\n",
    "            y_root = Find(y)\n",
    "            if x_root == y_root:\n",
    "                return x_root\n",
    "\n",
    "            if x_root.rank < y_root.rank:\n",
    "                x_root.parent = y_root\n",
    "                return y_root\n",
    "            elif x_root.rank > y_root.rank:\n",
    "                y_root.parent = x_root\n",
    "                return x_root\n",
    "            else:\n",
    "                y_root.parent = x_root\n",
    "                x_root.rank += 1\n",
    "                return x_root\n",
    "\n",
    "        # apply Connected Component algorithm, comparing SWT values.\n",
    "        # components with a SWT ratio less extreme than 1:3 are assumed to be\n",
    "        # connected. Apply twice, once for each ray direction/orientation, to\n",
    "        # allow for dark-on-light and light-on-dark texts\n",
    "        trees = {}\n",
    "        # Assumption: we'll never have more than 65535-1 unique components\n",
    "        label_map = np.zeros(shape=swt.shape, dtype=np.uint16)\n",
    "        next_label = 1\n",
    "        # First Pass, raster scan-style\n",
    "        swt_ratio_threshold = 3.0\n",
    "        for y in range(swt.shape[0]):\n",
    "            for x in range(swt.shape[1]):\n",
    "                sw_point = swt[y, x]\n",
    "                if sw_point < np.Infinity and sw_point > 0:\n",
    "                    neighbors = [(y, x-1),   # west\n",
    "                                 (y-1, x-1), # northwest\n",
    "                                 (y-1, x),   # north\n",
    "                                 (y-1, x+1)] # northeast\n",
    "                    connected_neighbors = None\n",
    "                    neighborvals = []\n",
    "\n",
    "                    for neighbor in neighbors:\n",
    "                        # west\n",
    "                        try:\n",
    "                            sw_n = swt[neighbor]\n",
    "                            label_n = label_map[neighbor]\n",
    "                        except IndexError:\n",
    "                            continue\n",
    "                        if label_n > 0 and sw_n / sw_point < swt_ratio_threshold and sw_point / sw_n < swt_ratio_threshold:\n",
    "                            neighborvals.append(label_n)\n",
    "                            if connected_neighbors:\n",
    "                                connected_neighbors = Union(connected_neighbors, MakeSet(label_n))\n",
    "                            else:\n",
    "                                connected_neighbors = MakeSet(label_n)\n",
    "\n",
    "                    if not connected_neighbors:\n",
    "                        # We don't see any connections to North/West\n",
    "                        trees[next_label] = (MakeSet(next_label))\n",
    "                        label_map[y, x] = next_label\n",
    "                        next_label += 1\n",
    "                    else:\n",
    "                        # We have at least one connection to North/West\n",
    "                        label_map[y, x] = min(neighborvals)\n",
    "                        # For each neighbor, make note that their respective connected_neighbors are connected\n",
    "                        # for label in connected_neighbors. @todo: do I need to loop at all neighbor trees?\n",
    "                        trees[connected_neighbors.value] = Union(trees[connected_neighbors.value], connected_neighbors)\n",
    "\n",
    "        # Second pass. re-base all labeling with representative label for each connected tree\n",
    "        layers = {}\n",
    "        contours = defaultdict(list)\n",
    "        for x in range(swt.shape[1]):\n",
    "            for y in range(swt.shape[0]):\n",
    "                if label_map[y, x] > 0:\n",
    "                    item = ld[label_map[y, x]]\n",
    "                    common_label = Find(item).value\n",
    "                    label_map[y, x] = common_label\n",
    "                    contours[common_label].append([x, y])\n",
    "                    try:\n",
    "                        layer = layers[common_label]\n",
    "                    except KeyError:\n",
    "                        layers[common_label] = np.zeros(shape=swt.shape, dtype=np.uint16)\n",
    "                        layer = layers[common_label]\n",
    "\n",
    "                    layer[y, x] = 1\n",
    "        return layers\n",
    "\n",
    "    @classmethod\n",
    "    def _find_letters(cls, swt, shapes):\n",
    "        # STEP: Discard shapes that are probably not letters\n",
    "        swts = []\n",
    "        heights = []\n",
    "        widths = []\n",
    "        topleft_pts = []\n",
    "        images = []\n",
    "\n",
    "        for label,layer in shapes.items():\n",
    "            (nz_y, nz_x) = np.nonzero(layer)\n",
    "            east, west, south, north = max(nz_x), min(nz_x), max(nz_y), min(nz_y)\n",
    "            width, height = east - west, south - north\n",
    "\n",
    "            if width < 8 or height < 8:\n",
    "                continue\n",
    "\n",
    "            if width / height > 10 or height / width > 10:\n",
    "                continue\n",
    "\n",
    "            if float(width) / height > 3.0:\n",
    "                continue\n",
    "\n",
    "            diameter = math.sqrt(width * width + height * height)\n",
    "            median_swt = np.median(swt[(nz_y, nz_x)])\n",
    "            if diameter / median_swt > 10:\n",
    "                continue\n",
    "\n",
    "            if width / layer.shape[1] > 0.4 or height / layer.shape[0] > 0.4:\n",
    "                continue\n",
    "\n",
    "            if diagnostics:\n",
    "                cv2.imwrite('layer'+ str(label) +'.jpg', layer * 255)\n",
    "\n",
    "            # we use log_base_2 so we can do linear distance comparison later using k-d tree\n",
    "            # ie, if log2(x) - log2(y) > 1, we know that x > 2*y\n",
    "            # Assumption: we've eliminated anything with median_swt == 1\n",
    "            swts.append([math.log(median_swt, 2)])\n",
    "            heights.append([math.log(height, 2)])\n",
    "            topleft_pts.append(np.asarray([north, west]))\n",
    "            widths.append(width)\n",
    "            images.append(layer)\n",
    "\n",
    "        return swts, heights, widths, topleft_pts, images\n",
    "\n",
    "    @classmethod\n",
    "    def _find_words(cls, swts, heights, widths, topleft_pts, images):\n",
    "        # Find all shape pairs that have similar median stroke widths\n",
    "\n",
    "        #print 'SWTS'\n",
    "        #print swts\n",
    "        #print 'DONESWTS'\n",
    "\n",
    "        swt_tree = scipy.spatial.KDTree(np.asarray(swts))\n",
    "        stp = swt_tree.query_pairs(1)\n",
    "\n",
    "        # Find all shape pairs that have similar heights\n",
    "        height_tree = scipy.spatial.KDTree(np.asarray(heights))\n",
    "        htp = height_tree.query_pairs(1)\n",
    "\n",
    "        # Intersection of valid pairings\n",
    "        isect = htp.intersection(stp)\n",
    "\n",
    "        chains = []\n",
    "        pairs = []\n",
    "        pair_angles = []\n",
    "        for pair in isect:\n",
    "            left = pair[0]\n",
    "            right = pair[1]\n",
    "            widest = max(widths[left], widths[right])\n",
    "            distance = np.linalg.norm(topleft_pts[left] - topleft_pts[right])\n",
    "            if distance < widest * 1.5:\n",
    "                delta_yx = topleft_pts[left] - topleft_pts[right]\n",
    "                angle = np.arctan2(delta_yx[0], delta_yx[1])\n",
    "                if angle < 0:\n",
    "                    angle += np.pi\n",
    "\n",
    "                pairs.append(pair)\n",
    "                pair_angles.append(np.asarray([angle]))\n",
    "\n",
    "        atp = []\n",
    "        if len(pair_angles) > 0:\n",
    "            angle_tree = scipy.spatial.KDTree(np.asarray(pair_angles))\n",
    "            atp = angle_tree.query_pairs(np.pi/12)\n",
    "\n",
    "        for pair_idx in atp:\n",
    "            pair_a = pairs[pair_idx[0]]\n",
    "            pair_b = pairs[pair_idx[1]]\n",
    "            left_a = pair_a[0]\n",
    "            right_a = pair_a[1]\n",
    "            left_b = pair_b[0]\n",
    "            right_b = pair_b[1]\n",
    "\n",
    "            # @todo - this is O(n^2) or similar, extremely naive. Use a search tree.\n",
    "            added = False\n",
    "            for chain in chains:\n",
    "                if left_a in chain:\n",
    "                    chain.add(right_a)\n",
    "                    added = True\n",
    "                elif right_a in chain:\n",
    "                    chain.add(left_a)\n",
    "                    added = True\n",
    "            if not added:\n",
    "                chains.append(set([left_a, right_a]))\n",
    "            added = False\n",
    "            for chain in chains:\n",
    "                if left_b in chain:\n",
    "                    chain.add(right_b)\n",
    "                    added = True\n",
    "                elif right_b in chain:\n",
    "                    chain.add(left_b)\n",
    "                    added = True\n",
    "            if not added:\n",
    "                chains.append(set([left_b, right_b]))\n",
    "\n",
    "        word_images = []\n",
    "        for chain in [c for c in chains if len(c) > 1 and len(c) < 6]:\n",
    "            for idx in chain:\n",
    "                word_images.append(images[idx])\n",
    "                # cv2.imwrite('keeper'+ str(idx) +'.jpg', images[idx] * 255)\n",
    "                # final += images[idx]\n",
    "\n",
    "        return word_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c26c2212",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def getOcr(filename):\n",
    "    return image_to_string(Image.open(filename),config=\"--psm 8\") #4\n",
    "\n",
    "def run_swt_and_ocr(image, i, name, writefiles, outdir):\n",
    "    bib_number = None\n",
    "\n",
    "    if writefiles:\n",
    "        #cv2.imwrite(os.path.join(outdir, \"{}_2bibimage_{}.jpg\".format(i, name)), image)\n",
    "        cv2.imwrite(os.path.join(outdir, \"{}_2bibimage_{}.jpg\".format(i, name)), image)\n",
    "        \n",
    "\n",
    "    SWTbib = SWTScrubber.scrub(image)\n",
    "    if writefiles and SWTbib is not None:\n",
    "        SWTpath = os.path.join(outdir, \"{}_3SWTimage_{}.jpg\".format(i, name))\n",
    "        cv2.imwrite(SWTpath, (255 - (255 * SWTbib)))\n",
    "        bib_number = getOcr(SWTpath)\n",
    "        bib_number = re.sub(\"[^0-9]\", \"\", bib_number)\n",
    "\n",
    "    return bib_number\n",
    "\n",
    "\n",
    "def drawboxes(image, boxes, color=(0, 255, 0)):\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in boxes:\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "\n",
    "def getSubImage(image, rectangle):\n",
    "\n",
    "    (x, y, w, h) = rectangle\n",
    "\n",
    "    return image[y:y + h, x:x + w, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "450dbfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BodyDetector\n",
    "\n",
    "def getbodyboxes(image):\n",
    "\n",
    "    faces = findfaces(image)\n",
    "    bodyrectangles = findbodies(image, faces)\n",
    "\n",
    "    return bodyrectangles\n",
    "\n",
    "\n",
    "def findfaces(image):\n",
    "    cascPath = os.path.join(\"haarcascades\", \"haarcascade_frontalface_alt2.xml\")\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "    height, width, depth = image.shape\n",
    "    scale = 1\n",
    "    if width > 1024:\n",
    "        scale = 1024.0 / width\n",
    "        image = cv2.resize(image, None, fx=scale, fy=scale)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.05,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "    )\n",
    "\n",
    "    return [scale_rect(face, 1 / scale) for face in faces]\n",
    "\n",
    "\n",
    "def scale_rect(rect, scale):\n",
    "    return [int(value * scale) for value in rect]\n",
    "\n",
    "\n",
    "def findbodies(image, faces):\n",
    "    bodies = np.zeros_like(faces)\n",
    "    bodiesindex = 0\n",
    "\n",
    "    for (x, y, facewidth, faceheight) in faces:\n",
    "        bodyheight = 3 * faceheight\n",
    "        bodywidth = 7 / 3 * facewidth\n",
    "        y_body = y + faceheight + .5 * faceheight\n",
    "        x_body = x + .5 * facewidth - .5 * bodywidth\n",
    "\n",
    "        bodies[bodiesindex] = (x_body, y_body, bodywidth, bodyheight)\n",
    "        bodiesindex = bodiesindex + 1\n",
    "\n",
    "    return bodies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c02977e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BibTaggerResult(object):\n",
    "    def __init__(self):\n",
    "        self.faces = 0\n",
    "        self.bibs = 0\n",
    "        self.swt = 0\n",
    "        self.bib_numbers = []\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Result: {0} faces, {1} bibs, {2} SWT, {3} bib numbers: ({4})\".format(self.faces, self.bibs, self.swt,\n",
    "                                                                                     len(self.bib_numbers),\n",
    "                                                                                     self.bib_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f916b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rectangles(contours):\n",
    "    rectangles = []\n",
    "    for contour in contours:\n",
    "        epsilon = 0.04 * cv2.arcLength(contour, True)\n",
    "        hull = cv2.convexHull(contour)\n",
    "        approx = cv2.approxPolyDP(hull, epsilon, True)\n",
    "        if len(approx) == 4 and cv2.isContourConvex(approx):\n",
    "            rectangles.append(approx)\n",
    "\n",
    "    return rectangles\n",
    "\n",
    "def aspect_ratio(rect):\n",
    "  (x,y),(w,h),theta = cv2.minAreaRect(rect)\n",
    "  return float(w) / float(h)\n",
    "\n",
    "def is_potential_bib(rect, image_area):\n",
    "  min_bib_size = image_area / 12;\n",
    "  max_bib_size = image_area / 4;\n",
    "  return (cv2.contourArea(rect) > min_bib_size and\n",
    "          cv2.contourArea(rect) < max_bib_size and\n",
    "          aspect_ratio(rect) > 0.75 and\n",
    "          aspect_ratio(rect) < 2.5)\n",
    "\n",
    "\n",
    "def find_bib(image_1):\n",
    "\n",
    "    width, height, depth = image_1.shape\n",
    "\n",
    "    gray = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "\n",
    "    ret, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    threshold_contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    edges = cv2.Canny(gray, 175, 200, 3)\n",
    "    edge_contours, hierarchy = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = threshold_contours + edge_contours\n",
    "\n",
    "    rectangles = []\n",
    "    for contour in contours:\n",
    "        epsilon = 0.04 * cv2.arcLength(contour, True)\n",
    "        hull = cv2.convexHull(contour)\n",
    "        approx = cv2.approxPolyDP(hull, epsilon, True)\n",
    "        if (len(approx) == 4 and cv2.isContourConvex(approx)):\n",
    "            rectangles.append(approx)\n",
    "\n",
    "    potential_bibs = [rect for rect in rectangles if is_potential_bib(rect, width*height)]\n",
    "\n",
    "    ideal_aspect_ratio = 1.0\n",
    "        \n",
    "    potential_bibs = sorted(potential_bibs, key=lambda bib: abs(aspect_ratio(bib) - ideal_aspect_ratio))\n",
    "\n",
    "    return potential_bibs[0] if len(potential_bibs) > 0 else np.array([[(0, 0)], [(0, 0)], [(0, 0)], [(0, 0)]])\n",
    "\n",
    "\n",
    "class Bib(object):\n",
    "    def __init__(self, image, bodybox):\n",
    "        self.image = image\n",
    "        self.bodybox = bodybox\n",
    "        self.corners = find_bib(self.body_image())\n",
    "        x, y, w, h = cv2.boundingRect(self.corners)\n",
    "        self.bib_found = (x != 0 and y != 0 and w != 1 and h != 1)\n",
    "        self.number = None\n",
    "\n",
    "    def has_bib_number(self):\n",
    "        return self.number != None and self.number != ''\n",
    "\n",
    "    def body_image(self):\n",
    "        return getSubImage(self.image, self.bodybox)\n",
    "\n",
    "    def body_image_with_bib(self):\n",
    "        img = np.copy(self.body_image())\n",
    "        cv2.drawContours(img, [self.corners], -1, (0, 0, 255), 2)\n",
    "        return img\n",
    "\n",
    "    def corners_relative_to_main_image(self):\n",
    "        x_delta = self.bodybox[0]\n",
    "        y_delta = self.bodybox[1]\n",
    "        return np.array([[(pt[0][0] + x_delta, pt[0][1] + y_delta)] for pt in self.corners])\n",
    "\n",
    "    def smallest_subimage_containing_bib(self):\n",
    "        if not self.bib_found:\n",
    "            return self.body_image()\n",
    "\n",
    "        return getSubImage(self.body_image(), cv2.boundingRect(self.corners))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e4d9499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBibs(image, outdir):\n",
    "    writefiles = True\n",
    "    if (outdir == None):\n",
    "        writefiles = False\n",
    "    else:\n",
    "        if not os.path.exists(outdir):\n",
    "            os.makedirs(outdir)\n",
    "\n",
    "    bodyboxes = getbodyboxes(image)\n",
    "    imagecopy = np.copy(image)\n",
    "    drawboxes(imagecopy, bodyboxes)\n",
    "    if (writefiles):\n",
    "        cv2.imwrite(os.path.join(outdir, \"0_0bodyboxes.jpg\"), imagecopy)\n",
    "\n",
    "    bibs = [Bib(image, bodybox) for bodybox in bodyboxes]\n",
    "\n",
    "    if (writefiles):\n",
    "        for i, bib in enumerate(bibs):\n",
    "            cv2.imwrite(os.path.join(outdir, \"{}_1subimage.jpg\".format(i)), bib.body_image())\n",
    "            cv2.imwrite(os.path.join(outdir, \"{}_1subimage_withbib.jpg\".format(i)), bib.body_image_with_bib())\n",
    "\n",
    "    swtsuccesses = 0\n",
    "    for i, bib in enumerate(bibs):\n",
    "\n",
    "        SWTbib = None\n",
    "        try:\n",
    "            bibimage = bib.smallest_subimage_containing_bib()\n",
    "\n",
    "            height, width, depth = bibimage.shape\n",
    "            best_width = 256.0\n",
    "            scale = best_width / width\n",
    "\n",
    "            bibimage = cv2.resize(bibimage, None, fx=scale, fy=scale)\n",
    "            bib.number = run_swt_and_ocr(bibimage, i, \"normal\", writefiles, outdir)\n",
    "\n",
    "            if not bib.has_bib_number():\n",
    "                bibimage_inverted = (255 - bibimage)\n",
    "                bib.number = run_swt_and_ocr(bibimage_inverted, i, \"inverted\", writefiles, outdir)\n",
    "\n",
    "            if not bib.has_bib_number():\n",
    "                bibimage = cv2.cvtColor(bibimage_inverted, cv2.COLOR_BGR2GRAY);\n",
    "                bibimage = cv2.GaussianBlur(bibimage, (5, 5), 0)\n",
    "                bibimage = cv2.equalizeHist(bibimage)\n",
    "                ret, bibimage = cv2.threshold(bibimage, 75, 255, cv2.THRESH_BINARY);\n",
    "                bibimage = cv2.cvtColor(bibimage, cv2.COLOR_GRAY2BGR);\n",
    "                bibimage = cv2.fastNlMeansDenoisingColored(bibimage, None, 10, 10, 7, 21)\n",
    "                bib.number = run_swt_and_ocr(bibimage, i, \"inverted_and_normalized\", writefiles, outdir)\n",
    "\n",
    "            if SWTbib is not None:\n",
    "                swtsuccesses += 1\n",
    "\n",
    "        except Bib:\n",
    "            print(\"SWT failed\")\n",
    "\n",
    "    result = BibTaggerResult()\n",
    "    result.faces = len(bodyboxes)\n",
    "    result.bibs = sum(1 for bib in bibs if bib.bib_found)\n",
    "    result.swt = swtsuccesses\n",
    "    result.bib_numbers = [bib.number for bib in bibs if bib.has_bib_number()]\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74956fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tom\\AppData\\Local\\Temp/ipykernel_19284/51919488.py:61: RuntimeWarning: invalid value encountered in true_divide\n",
      "  grad_x_g = step_x_g / mag_g\n",
      "C:\\Users\\tom\\AppData\\Local\\Temp/ipykernel_19284/51919488.py:62: RuntimeWarning: invalid value encountered in true_divide\n",
      "  grad_y_g = step_y_g / mag_g\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 1 faces, 1 bibs, 0 SWT, 0 bib numbers: ([])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img = cv2.imread('./photos/GloryDays/17.jpg')\n",
    "result = findBibs(img,\"./photos-out\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8505268e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}